data:
  size: 48000 # steps = size / prompts_per_step = 48000 / 16 = 3000 steps
  specs:
    - name: spell_backward
      weight: 1
      config:
        min_word_len: 3
        max_word_len: 10

loss: ppo
model_name: Qwen/Qwen3-1.7B
clip_eps_lo: 0.2
clip_eps_hi: 0.2
clip_eps_val: 0.2
beta: 0.0  # when beta is set to 0, we don't load the reference model and skip KL penalty
lr: 5e-6
gamma: 0.99
lam: 0.95
vf_coef: 0.1
temperature: 0.6
top_p: 0.95
top_k: 20
min_p: 0.0
max_new_tokens: 512
prompts_per_step: 16
num_rollouts: 1  # for PPO num rollouts should be 1
rollout_batch_size: 8
train_batch_size: 2
batch_acc: 4
max_norm: 1.0
seed: 42
model_device_id: 0
ref_model_device_id: 1
val_model_device_id: 2
wandb_project: rlhf-book
wandb_run_name: ppo_spell_backwards
