# Process Reward Model (PRM) Pipeline
# Data → Model → Output → Loss

direction: right

title: "Process Reward Model (PRM)" {
  shape: text
  style.font-size: 24
  style.bold: true
}

# Data inputs
data: "Data" {
  shape: rectangle
  style.fill: "#e8f4f8"

  prompt: "prompt x"
  cot_steps: "CoT steps s₁...sₖ"
  label: "boundary labels\n{+1, 0, -1}"
}

# Model
model: "Model" {
  shape: rectangle
  style.fill: "#f0f0f0"

  trunk: "LM Trunk" {
    shape: rectangle
  }
  head: "Per-Token\n3-Class Head" {
    shape: rectangle
    style.fill: "#fff3cd"
  }

  trunk -> head
}

# Outputs
outputs: "Scores" {
  shape: rectangle
  style.fill: "#e8f4f8"

  step_scores: "step score\nat boundaries"
}

# Loss
loss: "Loss" {
  shape: rectangle
  style.fill: "#f8d7da"

  formula: "L = Σ CE(logits_t, label_t)\nwhere label ≠ -100" {
    shape: text
    style.font-size: 14
  }
}

# Connections
data -> model: "tokenize"
model -> outputs
outputs -> loss

# Annotation
note: "Step-boundary supervision\nNon-boundary masked\n3-class: correct/neutral/wrong" {
  shape: text
  style.font-size: 12
  style.italic: true
}
